<?xml version="1.0" encoding="UTF-8" ?>
<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="s_basis">
	<title>Bases</title>
	<introduction>
		<p>
			Now that we have the notions of span and linear independence in place, we simply combine them to define a <em>basis</em> of a vector space.
			In the spirit of <xref ref="s_span_independence"/>, a basis of a vector space <m>V</m> should be understood as a <em>minimal</em> spanning set.
		</p>

		<p>
			This section includes a number of theoretical results.
			There are two in particular that are worth highlighting, especially in regard to computational techniques for abstract vector spaces:
			<ol>
				<li>
					<p>
						If <m>B</m> is a basis of <m>V</m> containing exactly <m>n</m> elements, then any other basis <m>B'</m> also contains exactly <m>n</m> elements.
						(<xref ref="th_basis_dimension"/>)
					</p>
				</li>

				<li>
					<p>
						If <m>B</m> is a basis for <m>V</m>, then every element of <m>V</m> can be written as a linear combination of elements of <m>B</m> in a <em>unique way</em>.
						(<xref ref="th_basis_equivalence"/>)
					</p>
				</li>
			</ol>
			The first result allows us to define the <em>dimension</em> of a vector space as the number of elements in any given basis.
			The second result allows us to take any <m>n</m>-dimensional vector space <m>V</m> with chosen basis <m>B=\{\boldv_1, \boldv_2, \dots, \boldv_n\}</m> and effectively identify vectors <m>\boldv\in V</m> with the sequence <m>(c_1,c_2,\dots, c_n)\in \R^n</m>, where
			<me>
				\boldv=c_1\boldv_1+c_2\boldv_2+\cdots c_n\boldv_n
			</me>.
			This observation has the following consequence: given any <m>n</m>-dimensional vector space <m>V</m>, no matter how exotic, once we choose a basis <m>B</m> of <m>V</m>, we can reduce any and all linear algebraic questions or computations about <m>V</m> to a corresponding question in <m>\R^n</m>.
			We will elaborate this idea further in <xref ref="s_coordinatevectors"/>.
		</p>
	</introduction>

	<subsection xml:id="ss_bases">
		<title>Bases of vector spaces</title>
		<definition xml:id="d_basis">
			<title>Basis</title>
			<idx><h>basis</h><h>of a vector space</h></idx>
			<statement>
				<p>
					A subset <m>B</m> of a vector space <m>V</m> is called a <term>basis</term> if
					<ol marker="i">
						<li>
							<p>
								<m>B</m> spans <m>V</m>, and
							</p>
						</li>

						<li>
							<p>
								<m>B</m> is linearly independent.
							</p>
						</li>
					</ol>
					If the basis <m>B</m> comes equipped with an ordering (<ie />, <m>B</m> is an ordered set), then we call <m>B</m> and <term>ordered basis</term>
				</p>
			</statement>
		</definition>

		<remark xml:id="rm_standard_bases">
			<title>Some standard bases</title>
			<p>
				The examples of standard spanning sets in <xref ref="rm_spanning_sets"/> are easily seen to be linearly independent, and hence are in fact bases.
				We list them again here, using the same notation, and refer to these as <em>standard bases</em> for the given spaces.
				<ul>
					<li>
						<title>Zero space</title>
						<p>
							Let <m>V=\{\boldzero\}</m>.
							The empty <m>B=\emptyset=\{ \}</m> is a basis for <m>V</m>.
							Note that <m>B=\emptyset</m> spans <m>V</m> by definition (<xref ref="d_span"/>), and it satisfies the defining implication of linear independence (<xref ref="d_linear_independence"/>) trivially.
						</p>
					</li>

					<li>
						<title>Tuples</title>
						<p>
							Let <m>V=\R^n</m>.
							The set <m>B=\{\bolde_1, \bolde_2,\dots, \bolde_n\}</m> is the standard basis of <m>\R^n</m>.
						</p>
					</li>

					<li>
						<title>Matrices</title>
						<p>
							Let <m>V=M_{mn}</m>.
							The set <m>B=\{E_{ij}\colon 1\leq i\leq m, 1\leq j\leq n\}</m> is the standard basis of <m>M_{mn}</m>.
						</p>
					</li>
				</ul>
			</p>
		</remark>

		<p>
			Just as with spanning sets, bases are not in general unique: in fact, for any nonzero vector space there are infinitely many different bases.
		</p>

		<example>
			<title>Some nonstandard bases</title>
			<statement>
				<p>
					For each <m>V</m> and <m>B</m> below, verify that <m>B</m> is a basis of <m>V</m>.
					<ol>
						<li>
							<p>
								<m>V=\R^2</m>,
								<m>B=\{(1,1), (1,-1)\}</m>.
							</p>
						</li>

						<li>
							<p>
								<m>V=M_{22}</m>,
								<me>
									B=\left\{ A_1=\begin{bmatrix}0\amp 1\\ 1\amp 1 \end{bmatrix} , A_2=\begin{bmatrix}1\amp 0\\ 1\amp 1 \end{bmatrix} , A_3=\begin{bmatrix}1\amp 1\\ 0\amp 1 \end{bmatrix} , A_4=\begin{bmatrix}1\amp 1\\ 1\amp 0 \end{bmatrix} \right\}
								</me>.
							</p>
						</li>
					</ol>
				</p>
			</statement>

			<solution>
				<p>
					Each verification amounts to showing, using the techniques from <xref ref="s_span_independence"/>, that the given <m>B</m> spans the given <m>V</m> and is linearly independent.
				</p>

				<ol>
					<li>
						<p>
							Since neither element of <m>B=\{(1,1), (1,-1)\}</m> is a scalar multiple of the other, the set is linearly independent.
							To see that <m>B</m> spans <m>\R^2</m> we show that for any <m>(c,d)\in \R^2</m> we have
							<me>
								a(1,1)+b(1,-1)=(c,d)
							</me>
							for some <m>a,b\in \R</m>.
							Indeed we may take <m>a=\frac{1}{2}(c+d)</m> and <m>b=\frac{1}{2}(c-d)</m>.
							(These formulas were obtained by solving the corresponding system of two equations in the unknowns <m>a</m> and <m>b</m>.)
						</p>
					</li>

					<li>
						<p>
							First we show that <m>B=\{A_1,A_2,A_3,A_4\}</m> spans <m>M_{22}</m>.
							Given an arbitrary element
							<me>
								A=\begin{bmatrix}a\amp b\\ c\amp d\end{bmatrix}
							</me>,
							we must show that there exist scalars <m>c_1,c_2,c_3,c_4\in \R</m> satisfying
							<me>
								c_1A_1+c_2A_2+c_3A_3+c_4A_4=A
							</me>.
							Expanding out the left side of the above equality, we would have
							<me>
								\begin{bmatrix}
								c_2+c_3+c_4 \amp c_1+c_3+c_4\\
								c_1+c_2+c_4\amp c_1+c_2+c_3
								\end{bmatrix}=
								\begin{bmatrix}
								a\amp b\\ c\amp d
								\end{bmatrix}
							</me>.
							Thus we have <m>A\in \Span B</m> if and only if the linear system with augmented matrix
							<me>
								\begin{amatrix}[rrrr|r]
								0\amp 1\amp 1\amp 1 \amp a\\
								1\amp 0\amp 1\amp 1 \amp b \\
								1\amp 1\amp 0 \amp 1 \amp c\\
								1\amp 1\amp 1\amp 0\amp d
								\end{amatrix}
							</me>
							is consistent.
							This augmented matrix row reduces to
							<me>
								\begin{amatrix}[rrrr|r]
								\boxed{1}\amp 0\amp 1\amp 1 \amp b\\
								0\amp \boxed{1}\amp 1\amp 1 \amp a \\
								0\amp 0\amp \boxed{1} \amp 1/2 \amp \frac{1}{2}(a+b-c)\\
								0\amp 0\amp 0\amp \boxed{1}\amp \frac{1}{3}(a+b+c-2d)
								\end{amatrix}
							</me>.
							Since there is no leading one in the last column, we see that the corresponding system is consistent, and thus <m>A\in \Span B</m>, as desired.
						</p>

						<p>
							Turning to linear independence of <m>B</m>, we now endeavor to show that the only solution to
							<me>
								c_1A_1+c_2A_2+c_3A_3+c_4A_4=\begin{bmatrix}
								0\amp 0\\ 0\amp 0
								\end{bmatrix}
							</me>
							is the trivial one <m>c_1=c_2=c_3=c_4=0</m>.
							Just as above, such a solution corresponds to a solution to the linear system with augmented matrix
							<me>
								\begin{amatrix}[rrrr|r]
								0\amp 1\amp 1\amp 1 \amp 0\\
								1\amp 0\amp 1\amp 1 \amp 0 \\
								1\amp 1\amp 0 \amp 1 \amp 0\\
								1\amp 1\amp 1\amp 0\amp 0
								\end{amatrix}
							</me>,
							which row reduces to
							<me>
								\begin{amatrix}[rrrr|r]
								\boxed{1}\amp 0\amp 1\amp 1 \amp 0\\
								0\amp \boxed{1}\amp 1\amp 1 \amp 0 \\
								0\amp 0\amp \boxed{1} \amp 1/2 \amp 0\\
								0\amp 0\amp 0\amp \boxed{1}\amp 0
								\end{amatrix}
							</me>.
							Since the first four columns of this matrix contain leading ones, none of the unknowns <m>c_i</m> is free, which means that <m>(c_1,c_2,c_3,c_4)=(0,0,0,0)</m> is the unique solution to the system.
							This proves that
							<me>
								c_1A_1+c_2A_2+c_3A_3+c_4A_4=\boldzero\implies c_1=c_2=c_3=c_4=0
							</me>,
							as desired.
						</p>
					</li>
				</ol>
			</solution>
		</example>

		<p>
			Proceeding directly from the definition, to show a set <m>B</m> is a basis of <m>V</m> we have to do two steps: (i) show <m>\Span B= V</m>; (ii) show that <m>B</m> is linearly independent.
			The following theorem offers gives rise to a one-step technique for proving <m>B</m> is a basis: show that every element of <m>V</m> can be written as a linear combination of elements of <m>B</m> in a <em>unique way</em>.
		</p>

		<theorem xml:id="th_basis_equivalence">
			<title>Basis equivalence</title>
			<statement>
				<p>
					Let <m>B</m> be a subset of the vector space <m>V</m>.
					The following statements are equivalent:
				</p>

				<ol>
					<li>
						<p>
							The set <m>B</m> is a basis of <m>V</m>
						</p>
					</li>

					<li>
						<p>
							Every element <m>\boldv\in V</m> can be written as a linear combination of elements of <m>B</m>, and furthermore this linear combination is unique: <ie />, if we have
							<me>
								\boldv=c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=d_1\boldv_1+d_2\boldv_2+\cdots +d_s\boldv_r
							</me>,
							for some distinct vectors <m>\boldv_i\in B</m>, then <m>c_i=d_i</m> for all <m>1\leq i\leq r</m>.
						</p>
					</li>
				</ol>
			</statement>


			<proof>
				<case>
					<title>Implication: <m>(1)\implies (2)</m></title>
					<p>
						Suppose <m>B</m> is a basis.
						By definition, <m>B</m> spans <m>V</m>, and so every element of <m>V</m> can be written as a linear combination of elements of <m>B</m>.
						It remains to show that this linear combination is unique in the sense described.
						This follows from the fact that <m>B</m> is linearly independent.
						Indeed, if
						<me>
							c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=d_1\boldv_1+d_2\boldv_2+\cdots +d_r\boldv_r
						</me>,
						then after some algebra we have
						<me>
							(c_1-d_1)\boldv_1+(c_2-d_2)\boldv_2+\cdots +(c_r-d_r)\boldv_r=\boldzero
						</me>.
						Since <m>B</m> is linearly independent and since the <m>\boldv_i</m> are distinct, we must have <m>c_i-d_j=0</m>, and hence <m>c_i=d_i</m> for all <m>1\leq i\leq r</m>.
					</p>
				</case>

				<case>
					<title>Implication: <m>(2)\implies (1)</m></title>
					<p>
						If <m>B</m> satisfies (2), then clearly it spans <m>V</m>.
						The uniqueness of linear combinations of elements of <m>B</m> now easily implies <m>B</m> is linearly independent:
						<md>
							<mrow>c_1\boldv_1+c_2\boldv_2+\cdots c_r\boldv_r=\boldzero \amp \implies
							c_1\boldv_1+c_2\boldv_2+\cdots c_r\boldv_r=0\boldv_1+0\boldv_2+\cdots 0\boldv_r</mrow>
							<mrow>  \amp \implies c_1=0, c_2=0, \dots, c_r=0 \amp \text{(by uniqueness condition)}</mrow>
						</md>.
					</p>
				</case>
			</proof>
		</theorem>

		<p>
			<xref ref="th_basis_equivalence"/> yields the following one-step technique for proving a set is a basis.
		</p>

		<algorithm xml:id="proc_basis_onestep">
			<title>One-step technique for bases</title>
			<statement>
				<p>
					Let <m>V</m> be a vector space.
					To prove a subset <m>B\subseteq V</m> is a basis it suffices to show that every <m>\boldv\in V</m> can be written as a linear combination of elements of <m>B</m> in a unique way, as specified in <xref ref="th_basis_equivalence"/>.
				</p>
			</statement>
		</algorithm>

		<example xml:id="eg_basis_onestep_R3">
			<title>One-step technique for <m>\R^3</m></title>
			<statement>
				<p>
					Use the one step technique to decide whether the set
					<me>
						S=\{\boldv_1=(1,1,-3), \boldv_2=(1,0,-1), \boldv_3=(-1,1,-1), \boldv_4=(1,2,1)\}
					</me>
					is a basis of <m>\R^3</m>.
				</p>
			</statement>

			<solution>
				<p>
					We ask whether for all elements <m>\boldy=(a,b,c)\in \R^3</m> we can write
					<men xml:id="eq_basis_onestep_R3">
						\boldy=c_1\boldv_1+c_2\boldv_2+c_3\boldv_3+c_4\boldv_4
					</men>
					for a unique choice of <m>c_1,c_2,c_3, c_4</m>.
					This is equivalent to asking whether the matrix equation
					<me>
						\underset{A}{\begin{amatrix}[rrrr]
						1\amp 1\amp -1\amp 1\\
						1\amp 0\amp 1\amp 2\\
						-3\amp -1\amp -1 \amp 1
						\end{amatrix}}\, \underset{\boldx}{\colvec{c_1\\ c_2\\ c_3\\ c_4}}=\underset{\boldy}{\colvec{a\\ b\\ c}}
					</me>.
					has a unique solution <m>\boldx=(c_1,c_2,c_3,c_4)</m> for any choice of <m>\boldy=(a,b,c)</m>.
					Performing Gaussian elimination on the corresponding augmented matrix yields
					<me>
						\begin{amatrix}[rrrr|r]
						1\amp 1\amp -1\amp 1\amp a \\
						1\amp 0\amp 1\amp 2\amp b\\
						-3\amp -1\amp -1 \amp 1 \amp c  \end{amatrix}
						\xrightarrow{\phantom{row}}U=
						\begin{amatrix}[rrrr|r]
						\boxed{1}\amp 1\amp -1\amp 1\amp a \\
						0\amp \boxed{1}\amp -2\amp -1\amp a-b\\
						0\amp 0\amp 0\amp \boxed{1} \amp (a+2b+c)/6
						\end{amatrix}
					</me>.
					Since the third column of <m>U</m> does not have a leading one, we conclude that the corresponding system has a free variable, and hence that for any given <m>(a,b,c)\in \R^3</m> the equation <xref ref="eq_basis_onestep_R3"/> has <em>either</em> no solutions (inconsistent) <em>or</em> infinitely many solutions.
					In particular, it is not true that there is always a <em>unique</em> solution.
					Thus <m>S</m> is not a basis according to the one-step technique.
				</p>

				<p>
					In fact, our Gaussian elimination analysis tells us exactly how <m>S</m> fails to be a basis.
					Since the last column of <m>U</m> does not have a leading one, the corresponding system is always consistent: <ie />, there is always at least one solution <m>\boldx=(c_1,c_2,c_3,c_4)</m> to <xref ref="eq_basis_onestep_R3"/> for each <m>(a,b,c)\in \R^3</m>.
					This tells us that <m>S</m> is a spanning set of <m>\R^3</m>.
					On the other hand, the existence of the free variable tells us that for <m>(a,b,c)=(0,0,0)=\boldzero</m>, we will have infinitely many choices <m>c_1,c_2,c_3,c_4</m> satisfying
					<me>
						c_1\boldv_1+c_2\boldv_2+c_3\boldv_3+c_4\boldv_4=\boldzero
					</me>.
					This shows that <m>S</m> is <em>not</em> linearly independent.
				</p>
			</solution>
		</example>

		<example xml:id="ss_vid_eg_basis">
			<title>Video example: deciding if a set is a basis</title>
			<figure xml:id="fig_vid_basis">
				<title>Video: deciding if a set is a basis (<m>\R^n</m>)</title>
				<caption>Video: deciding if a set is a basis (<m>\R^n</m>)</caption>
				<video xml:id="vid_basis" youtube="WL2DfblK1BI" />
			</figure>

			<figure xml:id="fig_vid_basis_exotic">
				<title>Video: deciding if a set is a basis</title>
				<caption>Video: deciding if a set is a basis</caption>
				<video xml:id="vid_basis_exotic" youtube="JvPn5X93lGw" />
			</figure>
		</example>

		<p>
			Besides deciding whether a given set is a basis, we will often want to come up with a basis of a given space on our own.
			The following <q>by inspection</q> technique often comes in handy in cases where the elements of the vector space can be described in a simple parametric manner.
		</p>

		<algorithm xml:id="proc_provide_basis">
			<title>By-inspection basis technique</title>
			<statement>
				<p>
					To produce a basis <m>B</m> of a vector space <m>V</m> <q>by inspection</q>, proceed as follows.
					<ol>
						<li>
							<title>Parametric description</title>
							<p>
								Give a simple parametric description of the general element of <m>V</m>.
							</p>
						</li>

						<li>
							<title>Spanning set</title>
							<p>
								If your parametric description is simple enough, you should be able to extract from it a natural spanning set <m>B</m> of <m>V</m>.
							</p>
						</li>

						<li>
							<title>Linear independence</title>
							<p>
								If your parametric description is free of redundancies, then <m>B</m> will likely be linearly independent.
								Verify this using <xref ref="proc_linear_independence"/>.
							</p>
						</li>
					</ol>
				</p>
			</statement>
		</algorithm>

		<example xml:base="eg_byinspection_R5">
			<title>By-inspection basis technique</title>
			<statement>
				<p>
					Use <xref ref="proc_provide_basis"/> to compute a basis of the subspace <m>W\subseteq \R^5</m> defined as
					<me>
						W=\{(x_1,x_2,x_3,x_4,x_5)\in \R^5\colon x_1+x_2=x_4-x_5=0\}
					</me>.
				</p>
			</statement>

			<solution>
				<p>
					The two equations
					<md>
						<mrow>x_1+x_2\amp =0 \amp x_4-x_5\amp =0 </mrow>
					</md>
					give two independent conditions on <m>x_1,x_2</m> and <m>x_4,x_5</m>, and no condition on <m>x_3</m>.
					We see that the general element of <m>W</m> can be described as
					<men xml:id="eq_basis_R5">
						(r,-r,s,t,t)=r\underset{\boldx_1}{\underbrace{(1,-1,0,0,0)}}+s\underset{\boldx_2}{\underbrace{(0,0,1,0,0)}}+t\underset{\boldx_3}{\underbrace{(0,0,0,1,1)}}
					</men>
					for arbitrary scalars <m>r,s,t</m>.
					It follows immediately that <m>B=\{\boldx_1,\boldx_2,\boldx_3\}</m> spans <m>W</m>.
					Furthermore, using <xref ref="eq_basis_R5"/>, we have
					<md>
						<mrow>c_1\boldx_1+c_2\boldx_2+c_3\boldx_3=\boldzero \amp\implies (c_1,-c_1,c_2,c_3,c_3)=(0,0,0,0,0,0) </mrow>
						<mrow> \amp \implies c_1=c_2=c_3=0</mrow>
					</md>
					for any scalars <m>c_1,c_2,c_3\in \R</m>.
					Thus <m>B</m> is linearly independent.
					We conclude <m>B</m> is a basis.
				</p>
			</solution>
		</example>

		<example xml:id="eg_byinspection_basis">
			<title>By-inspection basis technique</title>
			<statement>
				<p>
					Let <m>W\subseteq M_{22}</m> be the subspace of all symmetric matrices.
					Use <xref ref="proc_provide_basis"/> to compute a basis of <m>W</m>.
				</p>
			</statement>

			<solution>
				<p>
					We follow the three steps of <xref ref="proc_provide_basis"/>.
					<ol>
						<li>
							<p>
								A general <m>2\times 2</m> symmetric matrix can be described parametrically as
								<me>
									A=\begin{bmatrix}
									a\amp b\\ b\amp c
									\end{bmatrix}
								</me>.
							</p>
						</li>

						<li>
							<p>
								We have
								<men xml:id="eq_provide_basis">
									\begin{bmatrix}
									a\amp b\\ b\amp c
									\end{bmatrix}=
									a
									\begin{bmatrix}
									1\amp 0\\ 0\amp 0
									\end{bmatrix}
									+
									b
									\begin{bmatrix}
									0\amp 1\\ 1\amp 0
									\end{bmatrix}
									+
									c
									\begin{bmatrix}
									0\amp 0\\ 0\amp 1
									\end{bmatrix}
								</men>.
								It follows immediately that the set <m>B=\{A_1, A_2, A_3\}</m> is a spanning set, where
								<me>
									A_1=
									\begin{bmatrix}
									1\amp 0\\ 0\amp 0
									\end{bmatrix}, A_2=\begin{bmatrix}
									0\amp 1\\ 1\amp 0
									\end{bmatrix}
									, A_3=\begin{bmatrix}
									0\amp 0\\ 0\amp 1
									\end{bmatrix}
								</me>.
							</p>
						</li>

						<li>
							<p>
								The expression <xref ref="eq_provide_basis"/> tells us that
								<md>
									<mrow>aA_1+bA_2+cA_3 = \boldzero\amp \iff \begin{bmatrix}
									a\amp b\\ b\amp c
									\end{bmatrix}=\begin{bmatrix}
									0\amp 0\\ 0\amp 0
									\end{bmatrix} </mrow>
									<mrow> \amp\iff a=b=c=0 </mrow>
								</md>.
								This proves <m>B</m> is linearly independent.
							</p>
						</li>
					</ol>
					Since <m>B</m> is a linearly independent spanning set of <m>W</m>, it is a basis of <m>W</m>.
				</p>
			</solution>
		</example>
	</subsection>
	<xi:include href="./s_basis_ex.ptx"/>
</section>
